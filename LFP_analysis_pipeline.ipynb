{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth LFP Analysis Pipeline \n",
    "\n",
    "Welcome to the script for generating parameter dictionaries for the recording sessions in your experiment folder. Please follow the upcoming steps in this notebook for further instructions. \n",
    "\n",
    "## 1) Import the packages required for running the script\n",
    "\n",
    "Please run the block of code to import the Python packages that are required for running the rest of this script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import pickle as p \n",
    "import os\n",
    "from utils.load_intan_rhd_format import * \n",
    "from utils.reading_utils import *\n",
    "from tqdm import tqdm\n",
    "import ipywidgets\n",
    "from ipywidgets import Layout, HBox, VBox\n",
    "from IPython.display import display\n",
    "from glob import glob\n",
    "import importlib\n",
    "from utils.experiment_classes import *\n",
    "from utils.filtering import * \n",
    "import numpy as np\n",
    "import h5py\n",
    "from utils.notebook_utils import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Enter general parameters for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Creating widgets for the user input on the general parameters for the experiment\n",
    "\n",
    "##Main path for the data \n",
    "\n",
    "mp_html = ipywidgets.HTML(value = \"<p><b>Path to the data of the experiment:</b><br />Enter the path to the folder (with no '/' at the end) that is hierarchically right above the folders of the recording sessions</p>\")\n",
    "mp = ipywidgets.Text(value = \"\", placeholder = \"Enter path for data\", disabled = False)\n",
    "display(VBox([mp_html, mp]))\n",
    "\n",
    "##Type of the experiment\n",
    "\n",
    "et_html = ipywidgets.HTML(value = \"<b>Type of the experiment</b>\")\n",
    "et = ipywidgets.Dropdown(options=['Acute', 'Chronic'], \n",
    "                   value = 'Chronic',  disabled = False)\n",
    "display(VBox([et_html, et]))\n",
    "\n",
    "\n",
    "##File format\n",
    "ff_html = ipywidgets.HTML(value = \"<p><b>File format:</b><br />(dat for .dat, cont for .continuous, rhd for .rhd)</p>\")\n",
    "ff = ipywidgets.Text(value = 'dat', placeholder = 'Enter file format',\n",
    "             disabled = False)\n",
    "display(VBox([ff_html,ff]))\n",
    "\n",
    "##Amplifier port\n",
    "ap_html = ipywidgets.HTML(value = \"<b>The port to which the amplifier is connected</b>\")\n",
    "ap = ipywidgets.Dropdown(options=['A', 'B', 'C', 'D'], \n",
    "                   value = 'A',  disabled = False)\n",
    "display(VBox([ap_html, ap]))\n",
    "\n",
    "##Whisker Stim Path\n",
    "wsp = ipywidgets.IntText(value = 0, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the index of the digital input channel where the whisker stimulation trigger is kept</b>\"), wsp]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3) Enter parameters related to evoked LFP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating widgets for the user input on the parameters related to the whisker stim evoked LFP analysis\n",
    "\n",
    "##Downsampling factor\n",
    "ds = ipywidgets.IntText(value = 30, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the factor of downsampling the raw data prior to evoked LFP analysis. </b>\"), ds]))\n",
    "\n",
    "##whiskerEvokedPre\n",
    "\n",
    "wpre = ipywidgets.FloatText(value = 0.025, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter time taken prior to the whisker stimulus trigger (in s)</b>\"), wpre]))\n",
    "\n",
    "##whiskerEvokedPost\n",
    "\n",
    "wpost = ipywidgets.FloatText(value = 0.100, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter time taken post the whisker stimulus trigger (in s)</b>\"), wpost]))\n",
    "\n",
    "#low_pass_freq\n",
    "lp = ipywidgets.FloatText(value = 300, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b> Enter the cutoff frequency of the low pass filter to extract LFP from data (in Hz)\"), lp]))\n",
    "\n",
    "#Low pass filter order\n",
    "lp_order = ipywidgets.IntText(value = 4, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b> Enter the order of the Butterworth low pass filter used for the evoked LFP analysis (in Hz)\"), lp_order]))\n",
    "\n",
    "##cutBeginning\n",
    "cb = ipywidgets.FloatText(value = 1, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the time to be cut from the beginning of the recording (in s)</b>\"), cb]))\n",
    "\n",
    "##cutEnd\n",
    "ce = ipywidgets.FloatText(value = 1, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the time to be cut from the end of the recording (in s )\"), ce]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Enter parameters related to spike sorting\n",
    "\n",
    "If you are intending to do spike-sorting on this data, please set the spike-sorting parameters. Otherwise, set the boolean parameter \"do_spike_sorting\" to False below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating widgets for the user input on the parameters related to spike sorting\n",
    "\n",
    "##samplesBefore\n",
    "sb = ipywidgets.FloatText(value = 0.5, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = '<b>Enter the length of waveform to be taken before the threshold crossing (in ms)'), sb]))\n",
    "\n",
    "##samplesAfter\n",
    "sa = ipywidgets.FloatText(value = 1.5, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the length of waveform to be taken after the threshold crossing (in ms)\"), sa]))\n",
    "\n",
    "##lowCutoff\n",
    "lc = ipywidgets.FloatText(value = 300., disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the lower cutoff frequency for the bandpass filter to be applied on the raw data (in Hz)\"), lc]))\n",
    "\n",
    "##thresholdingCoefficient\n",
    "tc = ipywidgets.FloatText(value = 4.5, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the thresholding coefficient (in terms of multiple of baseline noise rms) to be used for spike detection\"), tc]))\n",
    "\n",
    "##Bandpass filter order \n",
    "fo = ipywidgets.IntText(value = 4)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the order of the Butterworth bandpass filter used on the raw data\"), fo]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5) Generate the parameters dictionaries\n",
    "\n",
    "Please run the block of the code in order to generate the parameters dictionary for each recording session (paramsDict.p) based on the input that you have provided above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if et.value == 'Acute':\n",
    "    experiment = acute(mp.value)\n",
    "    locations = glob(mp.value + '/loc*')\n",
    "    \n",
    "    for location in locations:\n",
    "        experiment.add_location(location)\n",
    "        \n",
    "    for location_index in experiment.locations:\n",
    "        location = experiment.locations[location_index]\n",
    "        location.add_sessions_in_dir()\n",
    "        \n",
    "        for session_index in location.sessions:\n",
    "            session = location.sessions[session_index]\n",
    "            session.setTrigChannels(wsp.value)\n",
    "            session.createProbe(pi.value)\n",
    "        \n",
    "    amplifier = experiment.locations[0].sessions[0].amplifier\n",
    "    if amplifier == 'rhd':\n",
    "        header_dir = experiment.locations[0].sessions[0].dir + '/info.rhd' \n",
    "            \n",
    "        \n",
    "elif et.value == 'Chronic':\n",
    "    experiment = chronic(mp.value)\n",
    "    days = glob(mp.value + '/20*')\n",
    "    experiment.createProbe('rhd', pi.value)\n",
    "    \n",
    "    for day in days:\n",
    "        experiment.add_day(day)\n",
    "        \n",
    "    for day_index in experiment.days:\n",
    "        day = experiment.days[day_index]\n",
    "        day.add_sessions_in_dir()\n",
    "        \n",
    "        for session_index in day.sessions:\n",
    "            session = day.sessions[session_index]\n",
    "            session.setTrigChannels(wsp.value)\n",
    "        \n",
    "header = read_data(header_dir)\n",
    "sr = header['frequency_parameters']['amplifier_sample_rate']\n",
    "\n",
    "#General parameters   \n",
    "experiment.fileformat = ff.value\n",
    "experiment.sample_rate = sr\n",
    "\n",
    "#Parameters related to spike sorting \n",
    "experiment.low_cutoff_bandpass = lc.value\n",
    "experiment.spike_samples_before = int(sb.value * experiment.sample_rate / 1000)\n",
    "experiment.spike_samples_after = int(sa.value * experiment.sample_rate / 1000)\n",
    "experiment.threshold_coeff = tc.value \n",
    "experiment.bandfilter_order = fo.value\n",
    "\n",
    "#Parameters related to evoked LFP analysis \n",
    "experiment.cut_beginning = cb.value \n",
    "experiment.cut_end = ce.value\n",
    "experiment.low_pass_freq = lp.value\n",
    "experiment.low_pass_order = lp_order.value \n",
    "experiment.whisker_evoked_pre = wpre.value\n",
    "experiment.whisker_evoked_post = wpost.value\n",
    "experiment.downsampling_factor = ds.value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Read and analyze stimulus evoked LFPs, generate dictionaries for spike sorting analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File(experiment.dir + '/analysis_results.hdf5', 'a')\n",
    "\n",
    "if experiment.type == 'acute': \n",
    "    experiment.probe = experiment.locations[0].sessions[0].probe\n",
    "\n",
    "    for location_index in experiment.locations:\n",
    "        location = experiment.locations[location_index]\n",
    "        print(\"Location: \" + location.name)\n",
    "        loc_grp = f.create_group(location.name)\n",
    "    \n",
    "        if experiment.probe.nr_of_electrodes_per_group == 1: \n",
    "            if not os.path.exists(location.dir + '/analysis_files'):\n",
    "                os.mkdir(location.dir + '/analysis_files/')\n",
    "        \n",
    "        for group in (range(experiment.probe.nr_of_groups)):\n",
    "            if not os.path.exists(location.dir + '/analysis_files'):\n",
    "                os.mkdir(location.dir + '/analysis_files/')\n",
    "            if not os.path.exists(location.dir + '/analysis_files/group_{:g}'.format(group)):\n",
    "                os.mkdir(location.dir + '/analysis_files/group_{:g}'.format(group))\n",
    "            if location.preferences['do_spike_analysis'] == 'y':\n",
    "                initialize_spike_sorting_notebook_for_group(location_index, location, group)\n",
    "            \n",
    "        for session_index in location.sessions: \n",
    "            session = location.sessions[session_index]\n",
    "            print(\"Session: \" + session.name)\n",
    "            ses_grp = loc_grp.create_group(session.name)\n",
    "            if (session.preferences['do_whisker_stim_evoked'] == 'y') or (session.preferences['do_optical_stim_evoked'] == 'y'):\n",
    "                stim_timestamps = read_stimulus_trigger(session)\n",
    "                for group in (range(experiment.probe.nr_of_groups)):\n",
    "                    print(\"Channel group: \" + str(group))\n",
    "                    ch_grp = ses_grp.create_group('group_{:g}'.format(group))\n",
    "                    read_evoked_lfp(group,session) \n",
    "                    \n",
    "if experiment.type == 'chronic': \n",
    "    for day_index in experiment.days:\n",
    "        day = experiment.days[day_index]\n",
    "        print(\"Day: \" + day.name)\n",
    "        day_grp = f.create_group(day.name)\n",
    "        \n",
    "        if not os.path.exists(day.dir + '/analysis_files'):\n",
    "            os.mkdir(day.dir + '/analysis_files/')\n",
    "            \n",
    "        for group in (range(experiment.probe.nr_of_groups)):\n",
    "            if experiment.probe.nr_of_electrodes_per_group != 1 and not os.path.exists(day.dir + '/analysis_files/group_{:g}'.format(group)):                     \n",
    "                os.mkdir(day.dir + '/analysis_files/group_{:g}'.format(group))\n",
    "            if day.preferences['do_spike_analysis'] == 'y':\n",
    "            \n",
    "            for session_index in day.sessions: \n",
    "                session = day.sessions[session_index]\n",
    "                session.probe = experiment.probe\n",
    "                print(\"Session: \" + session.name)\n",
    "                ses_grp = day_grp.create_group(session.name)\n",
    "                if (session.preferences['do_whisker_stim_evoked'] == 'y'):\n",
    "                    stim_timestamps = read_stimulus_trigger(session)\n",
    "                    for group in (range(experiment.probe.nr_of_groups)):\n",
    "                        print(\"Channel group: \" + str(group))\n",
    "                        ch_grp = ses_grp.create_group('group_{:g}'.format(group))\n",
    "                        read_evoked_lfp(group,session)                     \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(experiment, open((mp.value + '/experiment_params.p'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Add new days for the chronic recording experiments (Start from here if files for this experiment had already been generated before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "main_folder = '/home/baran/Dropbox (Yanik Lab)/Layer 1 Project/Electrophysiology/Experiments/mBY03'\n",
    "experiment_file = open((main_folder + '/experiment_params.p'), 'rb')\n",
    "experiment = pickle.load(experiment_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining the days that are already saved in the experiment dictionary\n",
    "existing_days = []\n",
    "for i in range(len(experiment.days)):\n",
    "    existing_days.append(experiment.days[i].name)\n",
    "\n",
    "#Adding the new days of recording since the last analysis\n",
    "days = glob(main_folder + '/20*')\n",
    "for day in days:\n",
    "    day_date = day[-8:]\n",
    "    if day_date not in existing_days:\n",
    "        experiment.add_day(day)\n",
    "        \n",
    "for day_index in experiment.days:\n",
    "    day = experiment.days[day_index]\n",
    "    if day.name not in existing_days:\n",
    "        day.add_sessions_in_dir()\n",
    "        \n",
    "        for session_index in day.sessions:\n",
    "            session = day.sessions[session_index]\n",
    "            session.setTrigChannels(0)\n",
    "    else:\n",
    "        pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook written by Baran Yasar in 04/2017. Please contact him in person or e-mail at yasar@biomed.ee.ethz.ch in case of any questions. \n",
    "\n",
    "---Updated in 07/2018 by Baran Yasar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {
    "1417bfb39df64cd88f56244ed1a2ce68": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "2016448bc3c045509135330b6ee6de1b": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "2db83e46a1154052bc68f74cd9c9a951": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "3083178c880e4cb59c87c8d759c68d2e": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "31a97b12e2334d589f19fc6650c2df48": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "3487e6ddae9d4d73ba08b2b1e9e33068": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "48724af7741f463b8bf18e7411f8063b": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "6e57b26f80fb4dc88b4361bdd3023152": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "79ba7984f6524d81a9f39f048fa2bbac": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "832fba406c604bc8999961633f70a238": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "89997f4b26d9460bbd0cae0a293bfac2": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "8a667b24238b4e2e81ab447624a36273": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "8f918ec1df0c407da4bee046556e3dfc": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "974de105baac476ea048e17b6a4d08f9": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "9c712e7664b4476c934e305a9f0df5da": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "a3462058cf5e46ecb16c0399e36bbaa9": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "dcdd3127b48642e780456d0066633ca0": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "e4b0d9933a154df19370581f45f5ca03": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f15cfed0e8754121a5d1c9fb31959a8e": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
