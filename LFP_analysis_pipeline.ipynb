{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth LFP Analysis Pipeline \n",
    "\n",
    "Welcome to the script for generating parameter dictionaries for the recording sessions in your experiment folder. Please follow the upcoming steps in this notebook for further instructions. \n",
    "\n",
    "## 1) Import the packages required for running the script\n",
    "\n",
    "Please run the block of code to import the Python packages that are required for running the rest of this script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import os, ipywidgets, pickle, h5py, shutil\n",
    "from utils.load_intan_rhd_format import * \n",
    "from utils.reading_utils import *\n",
    "from ipywidgets import Layout, HBox, VBox\n",
    "from IPython.display import display\n",
    "from utils.experiment_classes import *\n",
    "from utils.filtering import * \n",
    "from spikeSortingUtils.klusta_pre_and_post_processing_utils import * \n",
    "from utils.notebook_utils import * \n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Enter general parameters for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad96bc6f2a248f49f81ea2b666c15f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<p><b>Path to the data of the experiment:</b><br />Enter the path to the folder (wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e0e82f3dd14b5ab1b3d0f26579b026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p><b>File format:</b><br />(dat for .dat, cont for .continuous, rhd for .rhd)</p>'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41cb86b3c1a64388a8f88e64a743b92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>The port to which the amplifier is connected</b>'), Dropdown(options=('A', 'B', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7764190714465c9c299c2be5dbd17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter the index of the digital input channel where the whisker stimulation trigg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfeaac4221841ab93fdcda0514db154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Probe name:</b>'), Text(value='64_channel_single_shank_v2', placeholder='probe_f…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating widgets for the user input on the general parameters for the experiment\n",
    "\n",
    "##Main path for the data \n",
    "\n",
    "mp_html = ipywidgets.HTML(value = \"<p><b>Path to the data of the experiment:</b><br />Enter the path to the folder (with no '/' at the end) that is hierarchically right above the folders of the recording sessions</p>\")\n",
    "mp = ipywidgets.Text(value = \"folder\", placeholder = \"Enter path for data\", disabled = False)\n",
    "display(VBox([mp_html, mp]))\n",
    "\n",
    "##Type of the experiment\n",
    "\n",
    "#et_html = ipywidgets.HTML(value = \"<b>Type of the experiment</b>\")\n",
    "#et = ipywidgets.Dropdown(options=['Acute', 'Chronic'], \n",
    "#                   value = 'Chronic',  disabled = False)\n",
    "#display(VBox([et_html, et]))\n",
    "\n",
    "\n",
    "##File format\n",
    "ff_html = ipywidgets.HTML(value = \"<p><b>File format:</b><br />(dat for .dat, cont for .continuous, rhd for .rhd)</p>\")\n",
    "ff = ipywidgets.Text(value = 'dat', placeholder = 'Enter file format',\n",
    "             disabled = False)\n",
    "display(VBox([ff_html,ff]))\n",
    "\n",
    "##Amplifier port\n",
    "ap_html = ipywidgets.HTML(value = \"<b>The port to which the amplifier is connected</b>\")\n",
    "ap = ipywidgets.Dropdown(options=['A', 'B', 'C', 'D'], \n",
    "                   value = 'A',  disabled = False)\n",
    "display(VBox([ap_html, ap]))\n",
    "\n",
    "##Whisker Stim Path\n",
    "wsp = ipywidgets.IntText(value = 0, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the index of the digital input channel where the whisker stimulation trigger is kept</b>\"), wsp]))\n",
    "\n",
    "##Probe file path \n",
    "pi_html = ipywidgets.HTML(value = \"<b>Probe name:</b>\")\n",
    "pi = ipywidgets.Text(value = '64_channel_single_shank_v2', placeholder = 'probe_file',\n",
    "             disabled = False)\n",
    "display(VBox([pi_html,pi]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3) Enter parameters related to evoked LFP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1500f8de861d43a1b97549c7d0da3eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter the desired frequency of downsampled data for LFP analysis. </b>'), IntTex…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad68328cfc74f1594ea8b1b5b35ce58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter time taken prior to the whisker stimulus trigger (in s)</b>'), FloatText(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46717a543e324875bfa71218f9200d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter time taken post the whisker stimulus trigger (in s)</b>'), FloatText(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53749ed27e144ba6a81f2b15b40320d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b> Enter the cutoff frequency of the low pass filter to extract LFP from data (in …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5ee96083ec4211b3e6be5a5f35ab72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b> Enter the order of the Butterworth low pass filter used for the evoked LFP anal…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2a3edfc90c48d98516024ae792383c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter the time to be cut from the beginning of the recording (in s)</b>'), Float…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dfb245721f4c408ea611b1b6fa5617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter the time to be cut from the end of the recording (in s )'), FloatText(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating widgets for the user input on the parameters related to the whisker stim evoked LFP analysis\n",
    "\n",
    "##Downsampled frequency\n",
    "ds = ipywidgets.IntText(value = 1000, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the desired frequency of downsampled data for LFP analysis. </b>\"), ds]))\n",
    "\n",
    "##whiskerEvokedPre\n",
    "\n",
    "wpre = ipywidgets.FloatText(value = 0.025, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter time taken prior to the whisker stimulus trigger (in s)</b>\"), wpre]))\n",
    "\n",
    "##whiskerEvokedPost\n",
    "\n",
    "wpost = ipywidgets.FloatText(value = 0.100, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter time taken post the whisker stimulus trigger (in s)</b>\"), wpost]))\n",
    "\n",
    "#low_pass_freq\n",
    "lp = ipywidgets.FloatText(value = 300, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b> Enter the cutoff frequency of the low pass filter to extract LFP from data (in Hz)\"), lp]))\n",
    "\n",
    "#Low pass filter order\n",
    "lp_order = ipywidgets.IntText(value = 4, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b> Enter the order of the Butterworth low pass filter used for the evoked LFP analysis (in Hz)\"), lp_order]))\n",
    "\n",
    "##cutBeginning\n",
    "cb = ipywidgets.FloatText(value = 1, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the time to be cut from the beginning of the recording (in s)</b>\"), cb]))\n",
    "\n",
    "##cutEnd\n",
    "ce = ipywidgets.FloatText(value = 1, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the time to be cut from the end of the recording (in s )\"), ce]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Enter parameters related to spike sorting\n",
    "\n",
    "If you are intending to do spike-sorting on this data, please set the spike-sorting parameters. Otherwise, set the boolean parameter \"do_spike_sorting\" to False below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de946395179f41e2a38952544e8bfdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter the length of waveform to be taken before the threshold crossing (in ms)')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926af9b528f74c26afddb58a44cec5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter the length of waveform to be taken after the threshold crossing (in ms)'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03123eef0fbe44ea9b5b4672eb5ead51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter the lower cutoff frequency for the bandpass filter to be applied on the ra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5684e3d9ad4146c2a57d795ac80ecd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter the thresholding coefficient (in terms of multiple of baseline noise rms) …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f89ec0eb4194e02aca3fc12f310310e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter the order of the Butterworth bandpass filter used on the raw data'), IntTe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating widgets for the user input on the parameters related to spike sorting\n",
    "\n",
    "##samplesBefore\n",
    "sb = ipywidgets.FloatText(value = 0.5, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = '<b>Enter the length of waveform to be taken before the threshold crossing (in ms)'), sb]))\n",
    "\n",
    "##samplesAfter\n",
    "sa = ipywidgets.FloatText(value = 1.5, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the length of waveform to be taken after the threshold crossing (in ms)\"), sa]))\n",
    "\n",
    "##lowCutoff\n",
    "lc = ipywidgets.FloatText(value = 500., disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the lower cutoff frequency for the bandpass filter to be applied on the raw data (in Hz)\"), lc]))\n",
    "\n",
    "##thresholdingCoefficient\n",
    "tc = ipywidgets.FloatText(value = 4.5, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the thresholding coefficient (in terms of multiple of baseline noise rms) to be used for spike detection\"), tc]))\n",
    "\n",
    "##Bandpass filter order \n",
    "fo = ipywidgets.IntText(value = 4)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the order of the Butterworth bandpass filter used on the raw data\"), fo]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5) Generate the parameters dictionaries\n",
    "\n",
    "Please run the block of the code in order to generate the parameters dictionary for each recording session (paramsDict.p) based on the input that you have provided above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mBY05_awake_190909_165527\n",
      "Do spike detection, sorting and post-processing for this session? (y/n)y\n",
      "Do whisker stimulation evoked analysis for this session? (y/n)n\n",
      "Which channels will be used for software referencing to detect spikes?0,1,2,3,5,6,7,8,11,12,13,14,15,16,17,18,19,20,21,22,23,24\n",
      "Which channels are dead?25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63\n",
      "\n",
      "Reading Intan Technologies RHD2000 Data File, Version 1.5\n",
      "\n",
      "Found 64 amplifier channels.\n",
      "Found 3 auxiliary input channels.\n",
      "Found 1 supply voltage channel.\n",
      "Found 0 board ADC channels.\n",
      "Found 0 board digital input channels.\n",
      "Found 0 board digital output channels.\n",
      "Found 0 temperature sensors channels.\n",
      "\n",
      "Header file contains no data.  Amplifiers were sampled at 30.00 kS/s.\n",
      "Done!  Elapsed time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(mp.value)\n",
    "experiment.add_sessions_in_dir()\n",
    "\n",
    "for session_index in experiment.sessions:\n",
    "    session = experiment.sessions[session_index]\n",
    "    session.amplifier_port = ap.value\n",
    "    session.setTrigChannels(wsp.value)\n",
    "    \n",
    "    header_dir = session.dir + '/info.rhd'\n",
    "    header = read_data(header_dir)\n",
    "    session.sample_rate = header['frequency_parameters']['amplifier_sample_rate']\n",
    "    session.spike_samples_before = int(sb.value * session.sample_rate / 1000)\n",
    "    session.spike_samples_after = int(sa.value * session.sample_rate / 1000)\n",
    "    session.downsampling_factor = int(session.sample_rate / ds.value)\n",
    "    session.get_duration()\n",
    "\n",
    "experiment.amplifier = session.amplifier\n",
    "experiment.createProbe(mp.value, pi.value)   \n",
    "\n",
    "#General parameters   \n",
    "experiment.fileformat = ff.value\n",
    "\n",
    "#Parameters related to spike sorting \n",
    "experiment.low_cutoff_bandpass = lc.value\n",
    "experiment.threshold_coeff = tc.value \n",
    "experiment.bandfilter_order = fo.value\n",
    "\n",
    "#Parameters related to evoked LFP analysis \n",
    "experiment.cut_beginning = cb.value \n",
    "experiment.cut_end = ce.value\n",
    "experiment.low_pass_freq = lp.value\n",
    "experiment.low_pass_order = lp_order.value \n",
    "experiment.whisker_evoked_pre = wpre.value\n",
    "experiment.whisker_evoked_post = wpost.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Read and analyze stimulus evoked LFPs, generate dictionaries for spike sorting analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(mp.value)\n",
    "experiment = pickle.load(open('experiment_params.p', 'rb'))\n",
    "os.chdir(cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session:mBY05_awake_190909_165527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baran/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing data for spike sorting\n",
      "Channel group: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baran/Desktop/github/depth_recordings/spikeSortingUtils/klusta_pre_and_post_processing_utils.py:47: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if session.dead_channels != ['']:\n",
      "/home/baran/Desktop/github/depth_recordings/utils/reading_utils.py:156: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if (session.ref_channels != ['']):\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(experiment.dir + '/preprocessing_results.hdf5', 'a')\n",
    "preprocessing_files_dir = mp.value + '/preprocessing_files'\n",
    "\n",
    "#Create the folder for the preprocessing results\n",
    "if not os.path.exists(preprocessing_files_dir):\n",
    "    os.mkdir(preprocessing_files_dir)\n",
    "\n",
    "for session_index in experiment.sessions:\n",
    "    session = experiment.sessions[session_index]\n",
    "    print(\"session:\" + session.name)\n",
    "    \n",
    "    #Create the group for session in the hdf file\n",
    "    if session.name not in f:\n",
    "        ses_grp = f.create_group(session.name)\n",
    "        ds_lfp_grp = ses_grp.create_group(\"downsampled_lfp\") #Folder for the downsampled LFPs\n",
    "\n",
    "    #Create the folder for session in the preprocessing results folder\n",
    "    session_preprocessing_files_dir = preprocessing_files_dir + '/' + session.name\n",
    "    if not os.path.exists(session_preprocessing_files_dir):\n",
    "        os.mkdir(session_preprocessing_files_dir)\n",
    "    \n",
    "    #Create the group for channel groups in the hdf file\n",
    "    for group in range(experiment.probe.nr_of_groups):\n",
    "        ch_grp = ses_grp.create_group('group_{:g}'.format(group))\n",
    "        nr_of_electrodes = len(experiment.probe.id[group])\n",
    "        \n",
    "        probe_id = deepcopy(experiment.probe.id)\n",
    "        channels = probe_id[group]\n",
    "        if session.dead_channels != ['']:\n",
    "            for dead_channel in sorted(session.dead_channels, reverse=True):\n",
    "                channels.remove(dead_channel)\n",
    "        session.good_channels = channels\n",
    "        \n",
    "        for trode in channels:\n",
    "            electrode_data = read_channel(session, group, trode, [0,-1])\n",
    "            electrode_data = signal.decimate(electrode_data, session.downsampling_factor)\n",
    "            ds_lfp_grp.create_dataset(\"channel_{:g}_downsampled_LFP\".format(trode), data = electrode_data)    \n",
    "    \n",
    "    #Preprocessing evoked LFPs, if applicable\n",
    "    if session.preferences['do_whisker_stim_evoked'] == 'y':\n",
    "        print(\"Analyzing evoked LFPs\")\n",
    "        evoked_LFP_preprocessing_files_dir = session_preprocessing_files_dir + '/evoked_LFP_analysis'\n",
    "        if not os.path.exists(evoked_LFP_preprocessing_files_dir):\n",
    "            os.mkdir(evoked_LFP_preprocessing_files_dir)\n",
    "\n",
    "        read_stimulus_trigger(session)\n",
    "\n",
    "        for group in range(experiment.probe.nr_of_groups):\n",
    "            print(\"Channel group: \" + str(group))\n",
    "            read_evoked_lfp(group,session)\n",
    "    \n",
    "    #Preparing files for spike sorting, if applicable\n",
    "    if session.preferences['do_spike_analysis'] == 'y':\n",
    "        print(\"Pre-processing data for spike sorting\")\n",
    "        spike_sorting_preprocessing_files_dir = session_preprocessing_files_dir + '/spike_sorting'\n",
    "\n",
    "        if not os.path.exists(spike_sorting_preprocessing_files_dir):\n",
    "            os.mkdir(spike_sorting_preprocessing_files_dir)\n",
    "\n",
    "        for group in range(experiment.probe.nr_of_groups):\n",
    "            if not os.path.exists(spike_sorting_preprocessing_files_dir + '/group_{:}'.format(group)):\n",
    "                os.mkdir(spike_sorting_preprocessing_files_dir + '/group_{:}'.format(group))\n",
    "\n",
    "            print(\"Channel group: \" + str(group))\n",
    "            create_linear_prb_file(group, session)\n",
    "            create_prm_file(group, session)\n",
    "            read_group_into_dat_file(session, group, spike_sorting_preprocessing_files_dir)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(experiment, open((mp.value + '/experiment_params.p'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Add new days for the chronic recording experiments (Start from here if files for this experiment had already been generated before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = '/home/baran/Dropbox (Yanik Lab)/Layer 1 Project/Electrophysiology/Experiments/mBY05'\n",
    "sys.path.insert(0, main_folder)\n",
    "experiment_file = open((main_folder + '/experiment_params.p'), 'rb')\n",
    "experiment = pickle.load(experiment_file)\n",
    "f = h5py.File(experiment.dir + '/preprocessing_results.hdf5', 'r+')\n",
    "preprocessing_files_dir = experiment.dir + '/preprocessing_files'\n",
    "probe_name = str(experiment.probe.__class__).split('.')[1][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining the sessions that are already saved in the experiment dictionary\n",
    "existing_sessions = []\n",
    "for i in range(len(experiment.sessions)):\n",
    "    existing_sessions.append(experiment.sessions[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the new days of recording since the last analysis\n",
    "sessions = glob(main_folder + '/*[!preprocessing]')\n",
    "for session in sessions:\n",
    "    if session not in existing_sessions:\n",
    "        experiment.add_session(day)\n",
    "        \n",
    "for session_index in experiment.sessions:\n",
    "    session = experiment.sessions[session_index]\n",
    "    if session.name not in existing_sessions:\n",
    "        print(\"session:\" + session.name)\n",
    "        ses_grp = f.create_group(session.name)\n",
    "        experiment.add_sessions_in_dir()\n",
    "        \n",
    "        subExperiment_preprocessing_files_dir = preprocessing_files_dir + '/' + subExperiment.name\n",
    "        if not os.path.exists(subExperiment_preprocessing_files_dir):\n",
    "            os.mkdir(subExperiment_preprocessing_files_dir)\n",
    "        \n",
    "        for session_index in subExperiment.sessions:\n",
    "            session = subExperiment.sessions[session_index]\n",
    "            print(\"Session:\" + session.name)\n",
    "            ses_grp = subExperiment_grp.create_group(session.name)\n",
    "        \n",
    "            session_preprocessing_files_dir = subExperiment_preprocessing_files_dir + '/' + session.name\n",
    "            if not os.path.exists(session_preprocessing_files_dir):\n",
    "                os.mkdir(session_preprocessing_files_dir)\n",
    "        \n",
    "            for group in range(experiment.probe.nr_of_groups):\n",
    "                ch_grp = ses_grp.create_group('group_{:g}'.format(group))\n",
    "        \n",
    "            if session.preferences['do_whisker_stim_evoked'] == 'y':\n",
    "                print(\"Analyzing evoked LFPs\")\n",
    "                evoked_LFP_preprocessing_files_dir = session_preprocessing_files_dir + '/evoked_LFP_analysis'\n",
    "                if not os.path.exists(evoked_LFP_preprocessing_files_dir):\n",
    "                    os.mkdir(evoked_LFP_preprocessing_files_dir)\n",
    "            \n",
    "                stim_timestamps = read_stimulus_trigger(session)\n",
    "                for group in range(experiment.probe.nr_of_groups):\n",
    "                    print(\"Channel group: \" + str(group))\n",
    "                    read_evoked_lfp(group,session)\n",
    "        \n",
    "            if session.subExperiment.preferences['do_spike_analysis'] == 'y':\n",
    "                print(\"Pre-processing data for spike sorting\")\n",
    "                spike_sorting_preprocessing_files_dir = session_preprocessing_files_dir + '/spike_sorting'\n",
    "                if not os.path.exists(spike_sorting_preprocessing_files_dir):\n",
    "                    os.mkdir(spike_sorting_preprocessing_files_dir)\n",
    "            \n",
    "                for group in range(experiment.probe.nr_of_groups):\n",
    "                    if not os.path.exists(spike_sorting_preprocessing_files_dir + '/group_{:}'.format(group)):\n",
    "                        os.mkdir(spike_sorting_preprocessing_files_dir + '/group_{:}'.format(group))\n",
    "                    print(\"Channel group: \" + str(group))\n",
    "                    create_prm_file(group, session)\n",
    "                    create_linear_prb_file(group, session)\n",
    "                    read_group_into_dat_file(session, group, spike_sorting_preprocessing_files_dir)\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(experiment, open((main_folder + '/experiment_params.p'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook written by Baran Yasar in 04/2017. Please contact him in person or e-mail at yasar@biomed.ee.ethz.ch in case of any questions. \n",
    "\n",
    "---Updated in 07/2018 by Baran Yasar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {
    "1417bfb39df64cd88f56244ed1a2ce68": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "2016448bc3c045509135330b6ee6de1b": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "2db83e46a1154052bc68f74cd9c9a951": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "3083178c880e4cb59c87c8d759c68d2e": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "31a97b12e2334d589f19fc6650c2df48": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "3487e6ddae9d4d73ba08b2b1e9e33068": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "48724af7741f463b8bf18e7411f8063b": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "6e57b26f80fb4dc88b4361bdd3023152": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "79ba7984f6524d81a9f39f048fa2bbac": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "832fba406c604bc8999961633f70a238": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "89997f4b26d9460bbd0cae0a293bfac2": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "8a667b24238b4e2e81ab447624a36273": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "8f918ec1df0c407da4bee046556e3dfc": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "974de105baac476ea048e17b6a4d08f9": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "9c712e7664b4476c934e305a9f0df5da": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "a3462058cf5e46ecb16c0399e36bbaa9": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "dcdd3127b48642e780456d0066633ca0": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "e4b0d9933a154df19370581f45f5ca03": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f15cfed0e8754121a5d1c9fb31959a8e": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
