{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface LFP Analysis Pipeline \n",
    "\n",
    "Welcome to the script for generating parameter dictionaries for the recording sessions in your experiment folder. Please follow the upcoming steps in this notebook for further instructions. \n",
    "\n",
    "## 1) Import the packages required for running the script\n",
    "\n",
    "Please run the block of code to import the Python packages that are required for running the rest of this script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baran/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#Import required packages\n",
    "import pickle as p \n",
    "import os\n",
    "from utils.load_intan_rhd_format import * \n",
    "from utils.reading_utils import *\n",
    "from tqdm import tqdm\n",
    "import ipywidgets\n",
    "from ipywidgets import Layout, HBox, VBox\n",
    "from IPython.display import display\n",
    "from glob import glob\n",
    "import importlib\n",
    "from utils.experiment_classes import *\n",
    "from utils.filtering import * \n",
    "import numpy as np\n",
    "import h5py\n",
    "from spikeSortingUtils.custom_spike_sorting_utils import * \n",
    "from utils.notebook_utils import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Enter general parameters for the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating widgets for the user input on the general parameters for the experiment\n",
    "\n",
    "##Main path for the data \n",
    "\n",
    "mp_html = ipywidgets.HTML(value = \"<p><b>Path to the data of the experiment:</b><br />Enter the path to the folder (with no '/' at the end) that is hierarchically right above the folders of the recording sessions</p>\")\n",
    "mp = ipywidgets.Text(value = \"\", placeholder = \"Enter path for data\", disabled = False)\n",
    "display(VBox([mp_html, mp]))\n",
    "\n",
    "##Type of the experiment\n",
    "\n",
    "et_html = ipywidgets.HTML(value = \"<b>Type of the experiment</b>\")\n",
    "et = ipywidgets.Dropdown(options=['Acute', 'Chronic'], \n",
    "                   value = 'Acute',  disabled = False)\n",
    "display(VBox([et_html, et]))\n",
    "\n",
    "\n",
    "##File format\n",
    "ff_html = ipywidgets.HTML(value = \"<p><b>File format:</b><br />(dat for .dat, cont for .continuous, rhd for .rhd)</p>\")\n",
    "ff = ipywidgets.Text(value = 'dat', placeholder = 'Enter file format',\n",
    "             disabled = False)\n",
    "display(VBox([ff_html,ff]))\n",
    "\n",
    "##Number of probes\n",
    "\n",
    "nump_html = ipywidgets.HTML(value = \"<p><b>Number of probes:</b><br /><b>WARNING:</b>Pipeline currently supports <b>ONLY</b> the multiple probes being <b>IDENTICAL</b> in type and mapping!!! Pipeline has to be updated before using multiple probes of different types!</p>\")\n",
    "nump = ipywidgets.IntText(value = 1, disabled = False)\n",
    "display(VBox([nump_html, nump]))\n",
    "\n",
    "##Probe info\n",
    "pi_html = ipywidgets.HTML(value = \"<b>Probe used in the experiment</b>\")\n",
    "pi = ipywidgets.Dropdown(options=['thirty_channel_ecog', 'thirtytwo_channel_ecog', 'a4x8_5mm_100_200_177', 'a4x4_tet_150_200_1212', 'a2x16_10mm_100_500_177'], \n",
    "                   value = 'a2x16_10mm_100_500_177',  disabled = False)\n",
    "display(VBox([pi_html, pi]))\n",
    "\n",
    "##Amplifier port\n",
    "ap_html = ipywidgets.HTML(value = \"<b>The port to which the amplifier is connected</b>\")\n",
    "ap = ipywidgets.Dropdown(options=['A', 'B', 'C', 'D'], \n",
    "                   value = 'A',  disabled = False)\n",
    "display(VBox([ap_html, ap]))\n",
    "\n",
    "##Dead channels \n",
    "dc_html = ipywidgets.HTML(value = \"<p><b>Please enter dead channels with commas in between (e.g. 1,5,10,23) </b></p>\")\n",
    "dc = ipywidgets.Text(value = '', placeholder = 'Enter dead channels',\n",
    "             disabled = False)\n",
    "display(VBox([dc_html,dc]))\n",
    "\n",
    "##Whisker Stim Path\n",
    "\n",
    "wsp = ipywidgets.IntText(value = 1, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the index of the digital input channel where the whisker stimulation trigger is kept</b>\"), wsp]))\n",
    "\n",
    "##Optical Stim Path\n",
    "\n",
    "osp = ipywidgets.IntText(value = 1, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the index of the digital input channel where the optical stimulation trigger is kept</b>\"), osp]))\n",
    "\n",
    "##Electrical Stim Path\n",
    "\n",
    "esp = ipywidgets.IntText(value = 1, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the index of the digital input channel where the electrical stimulation trigger is kept</b>\"), esp]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3) Enter parameters related to evoked LFP analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating widgets for the user input on the parameters related to the whisker stim evoked LFP analysis\n",
    "\n",
    "##Downsampling factor\n",
    "ds = ipywidgets.IntText(value = 30, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the factor of downsampling the raw data prior to evoked LFP analysis. </b>\"), ds]))\n",
    "\n",
    "##whiskerEvokedPre\n",
    "\n",
    "wpre = ipywidgets.FloatText(value = 0.025, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter time taken prior to the whisker stimulus trigger (in s)</b>\"), wpre]))\n",
    "\n",
    "##whiskerEvokedPost\n",
    "\n",
    "wpost = ipywidgets.FloatText(value = 0.100, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter time taken post the whisker stimulus trigger (in s)</b>\"), wpost]))\n",
    "\n",
    "##lightEvokedPre\n",
    "\n",
    "lpre = ipywidgets.FloatText(value = 0.025, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter time taken prior to the optical stimulus trigger (in s)</b>\"), lpre]))\n",
    "\n",
    "##lightEvokedPost\n",
    "\n",
    "lpost = ipywidgets.FloatText(value = 0.100, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter time taken post the optical stimulus trigger (in s)</b>\"), lpost]))\n",
    "\n",
    "#low_pass_freq\n",
    "\n",
    "lp = ipywidgets.FloatText(value = 300, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b> Enter the cutoff frequency of the low pass filter to extract LFP from data (in Hz)\"), lp]))\n",
    "\n",
    "#Low pass filter order\n",
    "lp_order = ipywidgets.IntText(value = 4, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b> Enter the order of the Butterworth low pass filter used for the evoked LFP analysis (in Hz)\"), lp_order]))\n",
    "\n",
    "#notch_filt_freq\n",
    "\n",
    "nf = ipywidgets.FloatText(value = 0, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b> Enter the frequency of the notch filter (in Hz). Enter 0 if you don't want a notch filter\"), nf]))\n",
    "\n",
    "##cutBeginning\n",
    "\n",
    "cb = ipywidgets.FloatText(value = 1, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the time to be cut from the beginning of the recording (in s)</b>\"), cb]))\n",
    "\n",
    "##cutEnd\n",
    "\n",
    "ce = ipywidgets.FloatText(value = 1, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the time to be cut from the end of the recording (in s )\"), ce]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Enter parameters related to spike sorting\n",
    "\n",
    "If you are intending to do spike-sorting on this data, please set the spike-sorting parameters. Otherwise, set the boolean parameter \"do_spike_sorting\" to False below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating widgets for the user input on the parameters related to spike sorting\n",
    "\n",
    "##samplesBefore\n",
    "\n",
    "sb = ipywidgets.FloatText(value = 0.5, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = '<b>Enter the length of waveform to be taken before the threshold crossing (in ms)'), sb]))\n",
    "\n",
    "##samplesAfter\n",
    "\n",
    "sa = ipywidgets.FloatText(value = 1.5, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the length of waveform to be taken after the threshold crossing (in ms)\"), sa]))\n",
    "\n",
    "##lowCutoff\n",
    "\n",
    "lc = ipywidgets.FloatText(value = 500., disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the lower cutoff frequency for the bandpass filter to be applied on the raw data (in Hz)\"), lc]))\n",
    "\n",
    "##highCutoff\n",
    "\n",
    "hc = ipywidgets.FloatText(value = 5000., disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the higher cutoff frequency for the bandpass filter to be applied on the raw data (in Hz)\"), hc]))\n",
    "\n",
    "##chunkSize\n",
    "\n",
    "cs = ipywidgets.IntText(value = 60, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the chunk size (in s) for when reading the raw data to be processed for spike detection and sorting\"), cs]))\n",
    "\n",
    "##thresholdingCoefficient\n",
    "\n",
    "tc = ipywidgets.FloatText(value = 4.5, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the thresholding coefficient (in terms of multiple of baseline noise rms) to be used for spike detection\"), tc]))\n",
    "\n",
    "##minFrac\n",
    "\n",
    "mf = ipywidgets.FloatText(value = 0.01, disabled = False)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the minimum variance described by the principal components while applying PCA on the band-pass filtered data\"), mf]))\n",
    "\n",
    "##numClusters\n",
    "\n",
    "nc_html = ipywidgets.HTML(value = \"<b>Enter the number of initial seeds used for k-means clustering (three numbers separated by comma; one each for initial clustering, good clustering and better clustering)\")\n",
    "nc = ipywidgets.Text(value = '200,100,100', placeholder = 'Enter number of clusters',\n",
    "             disabled = False)\n",
    "display(VBox([nc_html,nc]))\n",
    "\n",
    "##Bandpass filter order \n",
    "\n",
    "fo = ipywidgets.IntText(value = 6)\n",
    "display(VBox([ipywidgets.HTML(value = \"<b>Enter the order of the Butterworth bandpass filter used on the raw data\"), fo]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5) Generate the parameters dictionaries\n",
    "\n",
    "Please run the block of the code in order to generate the parameters dictionary for each recording session (paramsDict.p) based on the input that you have provided above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dead_channels = np.asarray(dc.value.split(','))\n",
    "dead_channels = dead_channels.astype('int8')\n",
    "\n",
    "if et.value == 'Acute':\n",
    "    experiment = acute(mp.value)\n",
    "    locations = glob(mp.value + '/loc*')\n",
    "    \n",
    "    for location in locations:\n",
    "        experiment.add_location(location)\n",
    "        \n",
    "    for location_index in experiment.locations:\n",
    "        location = experiment.locations[location_index]\n",
    "        location.add_sessions_in_dir()\n",
    "        \n",
    "        for session_index in location.sessions:\n",
    "            session = location.sessions[session_index]\n",
    "            session.setTrigChannels(wsp.value, osp.value, esp.value)\n",
    "            session.createProbe(pi.value)\n",
    "            session.probe.remove_dead_channels(dead_channels)\n",
    "        \n",
    "    amplifier = experiment.locations[0].sessions[0].amplifier\n",
    "    if amplifier == 'rhd':\n",
    "        header_dir = experiment.locations[0].sessions[0].dir + '/info.rhd' \n",
    "            \n",
    "        \n",
    "elif et.value == 'Chronic':\n",
    "    experiment = chronic(mp.value)\n",
    "    days = glob(mp.value + '/20*')\n",
    "    \n",
    "    for day in days:\n",
    "        experiment.add_day(day)\n",
    "        \n",
    "    for day_index in experiment.days:\n",
    "        day = experiment.days[day_index]\n",
    "        day.add_sessions_in_dir()\n",
    "        \n",
    "        for session_index in day.sessions:\n",
    "            session = day.sessions[session_index]\n",
    "            session.setTrigChannels(wsp.value, osp.value, esp.value)\n",
    "            session.createProbe(pi.value)\n",
    "            session.probe.remove_dead_channels(dead_channels)\n",
    "    \n",
    "    amplifier = experiment.days[0].sessions[0].amplifier\n",
    "    if amplifier == 'rhd':\n",
    "        header_dir = experiment.days[0].sessions[0].dir + '/info.rhd'\n",
    "\n",
    "if amplifier == 'rhd':\n",
    "    header = read_data(header_dir)\n",
    "    sr = header['frequency_parameters']['amplifier_sample_rate']\n",
    "else: \n",
    "    sr=30000\n",
    "\n",
    "#General parameters   \n",
    "experiment.fileformat = ff.value\n",
    "experiment.sample_rate = sr\n",
    "\n",
    "#Parameters related to spike sorting \n",
    "experiment.low_cutoff_bandpass = lc.value\n",
    "experiment.high_cutoff_bandpass = hc.value\n",
    "experiment.spike_samples_before = int(sb.value * experiment.sample_rate / 1000)\n",
    "experiment.spike_samples_after = int(sa.value * experiment.sample_rate / 1000)\n",
    "experiment.chunk_size = cs.value \n",
    "experiment.threshold_coeff = tc.value \n",
    "experiment.min_frac = mf.value \n",
    "num_clusters = nc.value.split(',')\n",
    "num_clusters = np.asarray(num_clusters)\n",
    "experiment.num_clusters = num_clusters.astype('int8')\n",
    "experiment.bandfilter_order = fo.value\n",
    "experiment.bandfilt = bandpassFilter(rate = experiment.sample_rate, high = experiment.high_cutoff_bandpass, low = experiment.low_cutoff_bandpass, order = experiment.bandfilter_order, axis = 1)\n",
    "\n",
    "#Parameters related to evoked LFP analysis \n",
    "experiment.cut_beginning = cb.value \n",
    "experiment.cut_end = ce.value\n",
    "experiment.low_pass_freq = lp.value\n",
    "experiment.low_pass_order = lp_order.value \n",
    "experiment.notch_filt_freq = nf.value\n",
    "experiment.whisker_evoked_pre = wpre.value\n",
    "experiment.whisker_evoked_post = wpost.value\n",
    "experiment.light_evoked_pre = lpre.value\n",
    "experiment.light_evoked_post = lpost.value\n",
    "experiment.downsampling_factor = ds.value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle.dump(experiment, open((mp.value + '/experiment_params.p'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Read and analyze stimulus evoked LFPs, generate dictionaries for spike sorting analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: loc1\n",
      "Session: drybrain_spont_180709_163125\n",
      "Session: drybrain_spont_stim_spont_180709_165601\n",
      "Channel group: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 23 is out of bounds for axis 0 with size 23",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b207493dbf30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Channel group: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mch_grp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mses_grp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'group_{:g}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mread_evoked_lfp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreferences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'do_spike_analysis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0minitialize_spike_sorting_notebook_for_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/git-repos/surface_recording_project/LFPutils/read_evoked_lfp.py\u001b[0m in \u001b[0;36mread_evoked_lfp\u001b[0;34m(group, session)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreferences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'do_whisker_stim_evoked'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mwhisker_evoked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_evoked_lfp_from_stim_timestamps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhisker_stim_timestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'whisker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0manalyze_evoked_LFP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhisker_evoked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'whisker'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhisker_stim_grp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreferences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'do_optical_stim_evoked'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/git-repos/surface_recording_project/LFPutils/read_evoked_lfp.py\u001b[0m in \u001b[0;36manalyze_evoked_LFP\u001b[0;34m(evoked, session, group, mode, grp)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevoked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mtrode_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevoked_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 23 is out of bounds for axis 0 with size 23"
     ]
    }
   ],
   "source": [
    "experiment = pickle.load(open('/home/baran/Dropbox (Yanik Lab)/Layer 1 Project/Electrophysiology/Experiments/20180709_BY17_opto_ephys/experiment_params.p', 'rb'))\n",
    "\n",
    "f = h5py.File(experiment.dir + '/analysis_results.hdf5', 'a')\n",
    "experiment.probe = experiment.locations[0].sessions[0].probe\n",
    "\n",
    "for location_index in experiment.locations:\n",
    "    location = experiment.locations[location_index]\n",
    "    print(\"Location: \" + location.name)\n",
    "    loc_grp = f.create_group(location.name)\n",
    "    \n",
    "    for group in (range(experiment.probe.nr_of_groups)):\n",
    "        if not os.path.exists(location.dir + '/analysis_files'):\n",
    "            os.mkdir(location.dir + '/analysis_files/')\n",
    "        if not os.path.exists(location.dir + '/analysis_files/group_{:g}'.format(group)):\n",
    "            os.mkdir(location.dir + '/analysis_files/group_{:g}'.format(group))\n",
    "    \n",
    "    for session_index in location.sessions: \n",
    "        session = location.sessions[session_index]\n",
    "        print(\"Session: \" + session.name)\n",
    "        ses_grp = loc_grp.create_group(session.name)\n",
    "        if (session.preferences['do_whisker_stim_evoked'] == 'y') or (session.preferences['do_optical_stim_evoked'] == 'y'):\n",
    "            stim_timestamps = read_stimulus_trigger(session)\n",
    "            for group in (range(experiment.probe.nr_of_groups)):\n",
    "                print(\"Channel group: \" + str(group))\n",
    "                ch_grp = ses_grp.create_group('group_{:g}'.format(group))\n",
    "                read_evoked_lfp(group,session)\n",
    "        if location.preferences['do_spike_analysis'] == 'y':\n",
    "            initialize_spike_sorting_notebook_for_group(location_index, location, group)\n",
    "            \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook written by Baran Yasar in 04/2017. Please contact him in person or e-mail at yasar@biomed.ee.ethz.ch in case of any questions. \n",
    "\n",
    "---Updated in 07/2018 by Baran Yasar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {
    "1417bfb39df64cd88f56244ed1a2ce68": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "2016448bc3c045509135330b6ee6de1b": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "2db83e46a1154052bc68f74cd9c9a951": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "3083178c880e4cb59c87c8d759c68d2e": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "31a97b12e2334d589f19fc6650c2df48": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "3487e6ddae9d4d73ba08b2b1e9e33068": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "48724af7741f463b8bf18e7411f8063b": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "6e57b26f80fb4dc88b4361bdd3023152": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "79ba7984f6524d81a9f39f048fa2bbac": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "832fba406c604bc8999961633f70a238": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "89997f4b26d9460bbd0cae0a293bfac2": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "8a667b24238b4e2e81ab447624a36273": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "8f918ec1df0c407da4bee046556e3dfc": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "974de105baac476ea048e17b6a4d08f9": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "9c712e7664b4476c934e305a9f0df5da": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "a3462058cf5e46ecb16c0399e36bbaa9": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "dcdd3127b48642e780456d0066633ca0": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "e4b0d9933a154df19370581f45f5ca03": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f15cfed0e8754121a5d1c9fb31959a8e": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
